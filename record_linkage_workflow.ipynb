{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c096080cfaa734",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T09:10:57.058373600Z",
     "start_time": "2024-02-05T09:10:56.029774200Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from numpy.random import choice\n",
    "import faker\n",
    "import pandas as pd\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset is available in the [Google Drive](https://drive.google.com/file/d/1gviMipwq5MM_0O_gE02PsTq0-2tNGfbo/view?usp=sharing). Download it into the `data` folder."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1c79b2cf7bc3ee1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate names: 5.53%\n"
     ]
    },
    {
     "data": {
      "text/plain": "                     name                      email  \\\n0             Phillip Ray         eric97@example.com   \n1         Austin Martinez    ramosthomas@example.net   \n2        Caitlin Williams  alexisbridges@example.net   \n3             David Kline   nortonyvonne@example.net   \n4         Steven Phillips         sbarry@example.net   \n...                   ...                        ...   \n9999995    Gregory Nguyen     umacdonald@example.org   \n9999996     Ashley Fowler       sandra51@example.com   \n9999997       David Clark    collierlisa@example.net   \n9999998     Robert Foster    christian09@example.org   \n9999999     Lance Mendoza     jeremygray@example.org   \n\n                                                   address  \n0        5035 Mathis Squares Suite 555\\nEast Jenna, LA ...  \n1        1994 Emily Union Apt. 780\\nWest Kaylashire, ND...  \n2                  0873 Richard Curve\\nAdamsfurt, AK 91206  \n3                   120 Huber Isle\\nAntoniomouth, GA 03771  \n4        547 Donna Viaduct Apt. 585\\nNew Rubenview, GU ...  \n...                                                    ...  \n9999995     1080 Burke Groves Apt. 339\\nKyleberg, UT 50077  \n9999996  4812 Jason Junction Suite 359\\nLake Kimberly, ...  \n9999997    86943 Dave Road Suite 219\\nSmithmouth, AR 56196  \n9999998          59594 Harper Field\\nNorth Jason, TN 87310  \n9999999  00820 Michael Ranch Apt. 009\\nPatrickmouth, CT...  \n\n[10000000 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>email</th>\n      <th>address</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Phillip Ray</td>\n      <td>eric97@example.com</td>\n      <td>5035 Mathis Squares Suite 555\\nEast Jenna, LA ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Austin Martinez</td>\n      <td>ramosthomas@example.net</td>\n      <td>1994 Emily Union Apt. 780\\nWest Kaylashire, ND...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Caitlin Williams</td>\n      <td>alexisbridges@example.net</td>\n      <td>0873 Richard Curve\\nAdamsfurt, AK 91206</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>David Kline</td>\n      <td>nortonyvonne@example.net</td>\n      <td>120 Huber Isle\\nAntoniomouth, GA 03771</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Steven Phillips</td>\n      <td>sbarry@example.net</td>\n      <td>547 Donna Viaduct Apt. 585\\nNew Rubenview, GU ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9999995</th>\n      <td>Gregory Nguyen</td>\n      <td>umacdonald@example.org</td>\n      <td>1080 Burke Groves Apt. 339\\nKyleberg, UT 50077</td>\n    </tr>\n    <tr>\n      <th>9999996</th>\n      <td>Ashley Fowler</td>\n      <td>sandra51@example.com</td>\n      <td>4812 Jason Junction Suite 359\\nLake Kimberly, ...</td>\n    </tr>\n    <tr>\n      <th>9999997</th>\n      <td>David Clark</td>\n      <td>collierlisa@example.net</td>\n      <td>86943 Dave Road Suite 219\\nSmithmouth, AR 56196</td>\n    </tr>\n    <tr>\n      <th>9999998</th>\n      <td>Robert Foster</td>\n      <td>christian09@example.org</td>\n      <td>59594 Harper Field\\nNorth Jason, TN 87310</td>\n    </tr>\n    <tr>\n      <th>9999999</th>\n      <td>Lance Mendoza</td>\n      <td>jeremygray@example.org</td>\n      <td>00820 Michael Ranch Apt. 009\\nPatrickmouth, CT...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000000 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10_000_000\n",
    "\n",
    "dr = f'data'\n",
    "f = f'fake_data_people_{n}.parquet'\n",
    "\n",
    "filename = os.path.join(dr, f)\n",
    "if f not in os.listdir(dr):\n",
    "    fake = faker.Faker(seed=0, include_optional=[])\n",
    "    data = []\n",
    "    for i in trange(n):\n",
    "        data.append({\n",
    "            'name': fake.name() + choice([\"\", \" \" + fake.language_name()], p=[0.4, 0.6]),\n",
    "            'email': fake.email(),\n",
    "            'address': fake.address()\n",
    "        })\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_parquet(filename, index=False)\n",
    "\n",
    "df = pd.read_parquet(filename)\n",
    "print(f\"Number of duplicate names: {df['name'].value_counts().loc[lambda x: x > 1].shape[0] / df.shape[0] * 100:.2f}%\")\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T09:13:34.247584400Z",
     "start_time": "2024-02-05T09:13:23.151893Z"
    }
   },
   "id": "d5bc023786c93fda",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicated names: 553,473\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total duplicated names: {df['name'].value_counts().loc[lambda x: x > 1].shape[0]:,}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T09:15:51.905858200Z",
     "start_time": "2024-02-05T09:15:51.730772400Z"
    }
   },
   "id": "d1cd534fc2c82161",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicated emails: 1,061,303\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total duplicated emails: {df['email'].value_counts().loc[lambda x: x > 1].shape[0]:,}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T09:16:20.457826500Z",
     "start_time": "2024-02-05T09:16:19.920753300Z"
    }
   },
   "id": "f8a3d3e532ea1f2b",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['ssmith@example.com', 'hsmith@example.org', 'nsmith@example.com',\n       'dsmith@example.com', 'rsmith@example.org', 'psmith@example.com',\n       'csmith@example.org', 'ysmith@example.net', 'nsmith@example.org',\n       'ismith@example.org',\n       ...\n       'nicholsbrooke@example.net', 'phillipsanders@example.net',\n       'hayleyjohnson@example.net', 'reedluis@example.com',\n       'kimphilip@example.net', 'hamiltonadrian@example.com',\n       'loricoleman@example.net', 'davisvickie@example.org',\n       'carolynknapp@example.net', 'fisherkelli@example.org'],\n      dtype='object', name='email', length=1061303)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_unic_emails = df['email'].value_counts().loc[lambda x: x > 1].index\n",
    "non_unic_emails"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T09:18:05.473152100Z",
     "start_time": "2024-02-05T09:18:03.070425100Z"
    }
   },
   "id": "1e8f2f5786ff7cf5",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute candidate pairs: 0 days 00:00:29.282876\n",
      "Number of candidate pairs: 10,008,243\n"
     ]
    }
   ],
   "source": [
    "import recordlinkage\n",
    "time_start = pd.Timestamp.now()\n",
    "rules = [\n",
    "    {\"field\": \"name\", \"type\": \"Exact\", \"weight\": 50},\n",
    "    {\"field\": \"email\", \"type\": \"Exact\", \"weight\": 20},\n",
    "    {\"field\": \"address\", \"type\": \"Fuzzy\", \"weight\": 30}\n",
    "]\n",
    "\n",
    "comp = recordlinkage.Compare()\n",
    "\n",
    "comp.exact('name', 'name', agree_value=50)\n",
    "comp.exact('email', 'email', agree_value=20)\n",
    "comp.string('address', 'address', method='levenshtein', threshold=0.85)\n",
    "\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.block(left_on='name', right_on='name')\n",
    "indexer.block(left_on='email', right_on='email')\n",
    "candidate_pairs = indexer.index(df.sample(frac=0.1))\n",
    "time_end = pd.Timestamp.now()\n",
    "print(f\"Time to compute candidate pairs: {time_end - time_start}\")\n",
    "print(f\"Number of candidate pairs: {candidate_pairs.shape[0]:,}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T09:19:39.184777900Z",
     "start_time": "2024-02-05T09:19:09.873202Z"
    }
   },
   "id": "6e9f4b796a9a4c5f",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute scores: 0 days 00:02:46.291974\n",
      "Number of computed pairs: 10,008,243\n"
     ]
    }
   ],
   "source": [
    "time_start = pd.Timestamp.now()\n",
    "computed = comp.compute(candidate_pairs, df)\n",
    "computed.columns = ['name_score', 'email_score', 'address_score']\n",
    "computed['address_score_converted'] = computed['address_score'] * rules[2]['weight']\n",
    "computed['score'] = computed[['name_score', 'email_score', 'address_score_converted']].sum(axis=1)\n",
    "computed = computed.sort_values(by='score', ascending=False)\n",
    "computed = computed.reset_index()\n",
    "time_end = pd.Timestamp.now()\n",
    "print(f\"Time to compute scores: {time_end - time_start}\")\n",
    "print(f\"Number of computed pairs: {computed.shape[0]:,}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T09:23:31.602888600Z",
     "start_time": "2024-02-05T09:20:45.303467300Z"
    }
   },
   "id": "98043a3bdb162c5e",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prepare the final report"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f85510bc4f9f58a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "         Cluster Id  Cluster size  Score\n0                 5            13   20.0\n1                 5             4   50.0\n2                10             3   50.0\n3                18            13   50.0\n4                66             4   20.0\n...             ...           ...    ...\n1148963     9999942             4   20.0\n1148964     9999942             7   50.0\n1148965     9999973             2   50.0\n1148966     9999988             3   50.0\n1148967     9999990             8   50.0\n\n[1148968 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cluster Id</th>\n      <th>Cluster size</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>13</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>4</td>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10</td>\n      <td>3</td>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18</td>\n      <td>13</td>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>66</td>\n      <td>4</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1148963</th>\n      <td>9999942</td>\n      <td>4</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>1148964</th>\n      <td>9999942</td>\n      <td>7</td>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>1148965</th>\n      <td>9999973</td>\n      <td>2</td>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>1148966</th>\n      <td>9999988</td>\n      <td>3</td>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>1148967</th>\n      <td>9999990</td>\n      <td>8</td>\n      <td>50.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1148968 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computed_grouped = (computed.groupby(['level_0', 'score'])\n",
    "                    .agg(cluster_size = ('level_1', 'count'))\n",
    "                    .reset_index())\n",
    "computed_grouped.columns = ['Cluster Id', 'Score', 'Cluster size']\n",
    "computed_grouped = computed_grouped[['Cluster Id', 'Cluster size', 'Score']]\n",
    "computed_grouped"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T09:23:39.686267800Z",
     "start_time": "2024-02-05T09:23:38.976384900Z"
    }
   },
   "id": "2c79da0871885ad8",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What to do next? \n",
    "\n",
    "There is severa strategies to consider. \n",
    "\n",
    "Strategy 1: For the cases when there is much more the 5-10% of duplicated names, or other exact columns, we can consider to prefilter the daraset to remove the duplicated records before the linkage process.\n",
    "\n",
    "Strategy 2: Split dataset into **sorted** blocks and compare records only within the same block. This will reduce the number of comparisons and speed up the process. This strategy also adds the possibility to scale the process.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Extreme cases\n",
    "\n",
    "For the cases with huge datasets, we can consider to use approximate algorithms. These algorithms are able to find the similar records with high probability, but they are not able to find the exact matches. But this is the topic for another discussion."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aad7f2dce4190cda"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "fuzzo",
   "language": "python",
   "display_name": "fuzzo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
